{"cells":[{"cell_type":"markdown","id":"c4092a4f-40d8-41ee-abdb-576483aea3a0","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["# Install and Import"]},{"cell_type":"code","execution_count":null,"id":"50b61e74-9818-47e1-a7d7-4c4d38c600c5","metadata":{"jupyter":{"outputs_hidden":true,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["#%pip install google-api-python-client\n"]},{"cell_type":"code","execution_count":null,"id":"dcb3eeb8-f42c-420d-a342-f092cb1a1351","metadata":{},"outputs":[],"source":["import googleapiclient.discovery\n","import math\n","from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n","from pyspark.sql.functions import lit"]},{"cell_type":"markdown","id":"c2585113-7d2c-453f-85b2-d156fa6b693a","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["# Setup and initialise"]},{"cell_type":"code","execution_count":null,"id":"2e5c4929-fb39-4182-9b68-12177f75d1e5","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["api_service_name = \"youtube\"\n","api_version = \"v3\"\n","DEVELOPER_KEY = \"Your API Key here\"\n"]},{"cell_type":"code","execution_count":null,"id":"2dd8258d-8f6b-4f5f-a457-311b28c61d25","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["youtube = googleapiclient.discovery.build(\n","    api_service_name, api_version, developerKey = DEVELOPER_KEY)\n"]},{"cell_type":"markdown","id":"af2a38cb-949b-42be-9168-dcbe4b190aa5","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["# API Requests"]},{"cell_type":"code","execution_count":null,"id":"616fe824-e42c-4ed5-9d8e-afefe6dd648d","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["def convertResponseItemsToDataframe(items):\n","    \n","    # Create DataFrame\n","    schema = StructType([\n","        StructField(\"id\", StringType(), True),\n","        StructField(\"textDisplay\", StringType(), True),\n","        StructField(\"publishedAt\", StringType(), True),\n","        StructField(\"likeCount\", StringType(), True)\n","    ])\n","\n","    df = spark.createDataFrame([\n","        (\n","            d['id'], \n","            d['snippet']['topLevelComment']['snippet']['textDisplay'],\n","            d['snippet']['topLevelComment']['snippet']['publishedAt'],\n","            d['snippet']['topLevelComment']['snippet']['likeCount'],\n","        )\n","            for d in items],\n","        schema=schema\n","    )\n","    return df\n"]},{"cell_type":"code","execution_count":null,"id":"757c9e00-4900-44c1-a343-6a893cd25d2a","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["def getCommentThreads(videoId, commentCount, batchSize=100):\n","    requestCount = math.ceil((commentCount - batchSize)/batchSize)\n","    # Get first batch\n","    requestInit = youtube.commentThreads().list(\n","        part=\"id,snippet\",\n","        maxResults=batchSize,\n","        moderationStatus=\"published\",\n","        order=\"relevance\",\n","        videoId=videoId\n","    )\n","    responseInit = requestInit.execute()\n","    df = convertResponseItemsToDataframe(responseInit['items'])\n","    df = df.withColumn(\"videoId\", lit(videoId))\n","\n","\n","    #get subsequent requests\n","    i=1\n","    if commentCount > batchSize:\n","        previousResponseToken = responseInit['nextPageToken']\n","        while i <= requestCount:\n","            request = youtube.commentThreads().list(\n","                part=\"id,snippet\",\n","                maxResults=batchSize,\n","                moderationStatus=\"published\",\n","                order=\"relevance\",\n","                pageToken=previousResponseToken,\n","                videoId=videoId\n","            )\n","            response = request.execute()\n","            new_df = convertResponseItemsToDataframe(response['items'])\n","            new_df = new_df.withColumn(\"videoId\", lit(videoId))\n","            df = df.union(new_df)\n","\n","            if 'nextPageToken' in response:\n","                previousResponseToken = response['nextPageToken']\n","                i=i+1\n","            else:\n","                i=requestCount+1\n","\n","    return df"]},{"cell_type":"code","execution_count":null,"id":"dbebaa23-269a-47ae-8fb9-3504f99b5d86","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["videoIds = spark.sql(\"SELECT Id FROM Raw.videos\").rdd.flatMap(lambda x: x).collect()\n","\n","schema = StructType([\n","        StructField(\"id\", StringType(), True),\n","        StructField(\"textDisplay\", StringType(), True),\n","        StructField(\"publishedAt\", StringType(), True),\n","        StructField(\"likeCount\", StringType(), True),\n","        StructField(\"videoId\", StringType(), True)\n","])\n","\n","df = spark.createDataFrame(\n","    [],\n","    schema=schema\n",")\n","\n","for videoId in videoIds:\n","    print(f\"Getting comments for video: {videoId}\")\n","    newDf = getCommentThreads(videoId,10000)\n","    print(f\"Obtained {newDf.count()} comments for video {videoId}\")\n","    df = df.union(newDf)\n"]},{"cell_type":"markdown","id":"05706806-8ad0-405a-95b3-ab03772dd57d","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["### Convert data types"]},{"cell_type":"code","execution_count":null,"id":"bae26f41-f66c-4c31-bec7-d239d15794b9","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["df = df.withColumn('likeCount',df.likeCount.cast(IntegerType()))"]},{"cell_type":"markdown","id":"98cbd6b5-eec3-4b81-9c58-abc907e3dd58","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["# Write data"]},{"cell_type":"code","execution_count":null,"id":"2b7ae144-ed21-41f2-86aa-9552ee054906","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["df.write.mode(\"overwrite\").format(\"delta\").option(\"overwriteSchema\", \"true\").saveAsTable(\"Raw.comments\")"]}],"metadata":{"dependencies":{"environment":{"environmentId":"143044df-8d0d-4272-ae18-32804b812e76","workspaceId":"fd12376e-2797-4027-bb8e-42a3a8228a70"},"lakehouse":{"default_lakehouse":"77b89b44-1bcf-42fa-a9ac-7d0593123d3d","default_lakehouse_name":"Raw","default_lakehouse_workspace_id":"fd12376e-2797-4027-bb8e-42a3a8228a70"}},"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"display_name":"Synapse PySpark","language":"Python","name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default"},"synapse_widget":{"state":{},"version":"0.1"},"widgets":{}},"nbformat":4,"nbformat_minor":5}
